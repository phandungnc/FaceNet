{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbzuZw0I4jCg2jkP66o3ln"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDgz7oNtA3E7","executionInfo":{"status":"ok","timestamp":1749528999644,"user_tz":-420,"elapsed":1390,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"0e53559a-d18c-4798-c6db-01bf5823a9bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import os\n","import glob\n","import numpy as np\n","import cv2\n","\n","def load_train_lfw_data(data_dir):\n","    # Danh sách tất cả các tên thư mục (mỗi thư mục chứa các ảnh của một người)\n","    person_dirs = glob.glob(os.path.join(data_dir, '*'))\n","\n","    images = []\n","    names = []\n","\n","    for person_dir in person_dirs:\n","        person_name = os.path.basename(person_dir)  # Tên người\n","        image_paths = glob.glob(os.path.join(person_dir, '*.jpg'))\n","\n","        for img_path in image_paths:\n","            img = cv2.imread(img_path)  # Đọc ảnh với 3 kênh màu (RGB)\n","            img = cv2.resize(img, (224, 224))  # Resize về kích thước mong muốn\n","            images.append(img)\n","            names.append(person_name)\n","\n","    images = np.array(images)\n","    names = np.array(names)\n","\n","    return images, names\n","\n","data_dir = '/content/drive/MyDrive/Colab Notebooks/Train_ver3'\n","X, names = load_train_lfw_data(data_dir)"],"metadata":{"id":"Wz7LmYa8BJ8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encode nhãn thành số nguyên\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","names_encoded = le.fit_transform(names)\n","\n","# Lưu encoder để dùng sau\n","import joblib\n","joblib.dump(le, '/content/drive/MyDrive/label_encoder_ver3.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2AdcS-sesO6","executionInfo":{"status":"ok","timestamp":1749529007794,"user_tz":-420,"elapsed":1038,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"fd3da917-4667-4a6b-8294-2d798627abc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/label_encoder_ver3.pkl']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Chia train/test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, names_encoded, test_size=0.2, stratify=names_encoded)\n","\n","# Thông tin dữ liệu\n","print(X_train.shape, X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkuGdBKaewOp","executionInfo":{"status":"ok","timestamp":1749529008599,"user_tz":-420,"elapsed":143,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"af23887d-8df1-4042-ee5d-090673fb4a31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(772, 224, 224, 3) (194, 224, 224, 3)\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","    featurewise_center=True,          # Chuẩn hóa mean = 0\n","    featurewise_std_normalization=True, # Chuẩn hóa std = 1\n","    rotation_range=20,                # Xoay ảnh tối đa 20 độ\n","    width_shift_range=0.2,           # Dịch chuyển theo chiều rộng\n","    height_shift_range=0.2,          # Dịch chuyển theo chiều cao\n","    horizontal_flip=True,            # Lật ảnh theo chiều ngang\n","    #zoom_range=0.1,                  # Zoom ảnh\n","    brightness_range=[0.8, 1.2]     # Thay đổi độ sáng\n",")\n","\n","# Fit datagen với dữ liệu train\n","datagen.fit(X_train)"],"metadata":{"id":"icq__PMzmIPe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tạo dữ liệu augmented\n","X_augmented = []\n","y_augmented = []\n","\n","# Số lượng ảnh augmented cho mỗi ảnh gốc\n","augmented_per_image = 2\n","\n","print(f\"Tạo {augmented_per_image} ảnh biến thể cho mỗi ảnh gốc...\")\n","\n","for i in range(len(X_train)):\n","    if i % 100 == 0:  # In progress mỗi 100 ảnh\n","        print(f\"Đã xử lý {i}/{len(X_train)} ảnh...\")\n","\n","    # Thêm ảnh gốc vào tập augmented\n","    X_augmented.append(X_train[i])\n","    y_augmented.append(y_train[i])\n","\n","    # Tạo các ảnh biến thể\n","    no_img = 0\n","    for x_batch in datagen.flow(np.expand_dims(X_train[i], axis=0), batch_size=1):\n","        X_augmented.append(x_batch[0])\n","        y_augmented.append(y_train[i])\n","        no_img += 1\n","        if no_img == augmented_per_image:\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"co-ehqHzmhKr","executionInfo":{"status":"ok","timestamp":1749529036705,"user_tz":-420,"elapsed":20030,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"4edc09c6-2d48-474e-e4ff-e8d04461742d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tạo 2 ảnh biến thể cho mỗi ảnh gốc...\n","Đã xử lý 0/772 ảnh...\n","Đã xử lý 100/772 ảnh...\n","Đã xử lý 200/772 ảnh...\n","Đã xử lý 300/772 ảnh...\n","Đã xử lý 400/772 ảnh...\n","Đã xử lý 500/772 ảnh...\n","Đã xử lý 600/772 ảnh...\n","Đã xử lý 700/772 ảnh...\n"]}]},{"cell_type":"code","source":["X_train_model = np.array(X_augmented)\n","y_train_model= np.array(y_augmented)"],"metadata":{"id":"dLqpR6yfm0c-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(X_train_model), len(y_train_model))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRB4S1LuqrAF","executionInfo":{"status":"ok","timestamp":1749529037173,"user_tz":-420,"elapsed":17,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"91327dbe-d58a-4378-a388-e0711a2f1291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2316 2316\n"]}]},{"cell_type":"code","source":["!pip install tensorflow==2.15.0\n","!pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eGhrbN8YB42V","executionInfo":{"status":"ok","timestamp":1749528980499,"user_tz":-420,"elapsed":75512,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"93880fb2-1593-4bea-d10c-d280561ab53c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.15.0\n","  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n","Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n","  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n","  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.14.0)\n","Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n","  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.72.1)\n","Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n","  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.4.26)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n","Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tensorboard, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.17.2\n","    Uninstalling wrapt-1.17.2:\n","      Successfully uninstalled wrapt-1.17.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.8.0\n","    Uninstalling keras-3.8.0:\n","      Successfully uninstalled keras-3.8.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.18.0\n","    Uninstalling tensorboard-2.18.0:\n","      Successfully uninstalled tensorboard-2.18.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.18.0\n","    Uninstalling tensorflow-2.18.0:\n","      Successfully uninstalled tensorflow-2.18.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n","ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras","ml_dtypes","tensorflow","wrapt"]},"id":"5260dd96f1024ac4b57ae9854a8aea12"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 4.4.2\n","    Uninstalling typeguard-4.4.2:\n","      Successfully uninstalled typeguard-4.4.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","source":["# Tạo mô hình backbone\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Lambda, Flatten, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG16\n","\n","def _base_network():\n","    base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(224, 224, 3)))\n","\n","    #Mở 4 lớp cuối\n","    for layer in base_model.layers[:-4]:\n","        layer.trainable = False\n","    for layer in base_model.layers[-4:]:\n","        layer.trainable = True\n","\n","    x = Flatten()(base_model.output)\n","    x = Dense(128)(x)\n","    norm2 = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n","    model = Model(inputs=base_model.input, outputs=norm2)\n","    return model\n","\n","# Khởi tạo mô hình\n","model = _base_network()\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJIP0YKibu_0","executionInfo":{"status":"ok","timestamp":1749489011997,"user_tz":-420,"elapsed":769,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"dee4e976-da76-485e-d880-68d84ea76662"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 25088)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 128)               3211392   \n","                                                                 \n"," lambda_3 (Lambda)           (None, 128)               0         \n","                                                                 \n","=================================================================\n","Total params: 17926080 (68.38 MB)\n","Trainable params: 10290816 (39.26 MB)\n","Non-trainable params: 7635264 (29.13 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["print(X_train_model.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9DxCdxFq-ct","executionInfo":{"status":"ok","timestamp":1749529043503,"user_tz":-420,"elapsed":45,"user":{"displayName":"Dung Phan","userId":"07120578168330294972"}},"outputId":"6239b7ba-9602-4223-e593-80551505b894"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2316, 224, 224, 3)\n"]}]},{"cell_type":"code","source":["model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.0001),\n","    loss=tfa.losses.TripletSemiHardLoss()\n",")"],"metadata":{"id":"C---c-pse6f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 80\n","gen_train = tf.data.Dataset.from_tensor_slices((X_train_model, y_train_model)).shuffle(2048).batch(batch_size).repeat()"],"metadata":{"id":"gl-2AVfAfATr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpoint_callback = ModelCheckpoint(\n","    '/content/drive/MyDrive/facenet_ver4.h5',\n","    monitor='loss',\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='min',\n","    verbose=1\n",")"],"metadata":{"id":"XeYX0o3EfE-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    gen_train,\n","    steps_per_epoch=30,\n","    epochs=50,\n","    callbacks=[checkpoint_callback]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgaJ6W6rfHLp","outputId":"2d8bd4d2-adb3-41b2-a302-8ac9d399fc6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","30/30 [==============================] - ETA: 0s - loss: 0.9632  \n","Epoch 1: loss improved from 0.99260 to 0.96317, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1828s 61s/step - loss: 0.9632\n","Epoch 2/50\n","30/30 [==============================] - ETA: 0s - loss: 0.9233  \n","Epoch 2: loss improved from 0.96317 to 0.92327, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1847s 61s/step - loss: 0.9233\n","Epoch 3/50\n","30/30 [==============================] - ETA: 0s - loss: 0.8664  \n","Epoch 3: loss improved from 0.92327 to 0.86645, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1830s 61s/step - loss: 0.8664\n","Epoch 4/50\n","30/30 [==============================] - ETA: 0s - loss: 0.8188  \n","Epoch 4: loss improved from 0.86645 to 0.81878, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1850s 61s/step - loss: 0.8188\n","Epoch 5/50\n","30/30 [==============================] - ETA: 0s - loss: 0.7522  \n","Epoch 5: loss improved from 0.81878 to 0.75218, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1842s 61s/step - loss: 0.7522\n","Epoch 6/50\n","30/30 [==============================] - ETA: 0s - loss: 0.7001  \n","Epoch 6: loss improved from 0.75218 to 0.70006, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1846s 61s/step - loss: 0.7001\n","Epoch 7/50\n","30/30 [==============================] - ETA: 0s - loss: 0.6340  \n","Epoch 7: loss improved from 0.70006 to 0.63403, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1858s 62s/step - loss: 0.6340\n","Epoch 8/50\n","30/30 [==============================] - ETA: 0s - loss: 0.5743  \n","Epoch 8: loss improved from 0.63403 to 0.57430, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1843s 61s/step - loss: 0.5743\n","Epoch 9/50\n","30/30 [==============================] - ETA: 0s - loss: 0.5150  \n","Epoch 9: loss improved from 0.57430 to 0.51500, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1839s 61s/step - loss: 0.5150\n","Epoch 10/50\n","30/30 [==============================] - ETA: 0s - loss: 0.4773  \n","Epoch 10: loss improved from 0.51500 to 0.47732, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1850s 61s/step - loss: 0.4773\n","Epoch 11/50\n","30/30 [==============================] - ETA: 0s - loss: 0.4216  \n","Epoch 11: loss improved from 0.47732 to 0.42157, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1842s 61s/step - loss: 0.4216\n","Epoch 12/50\n","30/30 [==============================] - ETA: 0s - loss: 0.3894  \n","Epoch 12: loss improved from 0.42157 to 0.38940, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1830s 61s/step - loss: 0.3894\n","Epoch 13/50\n","30/30 [==============================] - ETA: 0s - loss: 0.3432  \n","Epoch 13: loss improved from 0.38940 to 0.34322, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1835s 61s/step - loss: 0.3432\n","Epoch 14/50\n","30/30 [==============================] - ETA: 0s - loss: 0.2981  \n","Epoch 14: loss improved from 0.34322 to 0.29809, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1827s 61s/step - loss: 0.2981\n","Epoch 15/50\n","30/30 [==============================] - ETA: 0s - loss: 0.2857  \n","Epoch 15: loss improved from 0.29809 to 0.28574, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1835s 61s/step - loss: 0.2857\n","Epoch 16/50\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","import tensorflow_addons as tfa\n","\n","model = load_model(\n","    '/content/drive/MyDrive/facenet_ver4.h5',\n","    custom_objects={'TripletSemiHardLoss': tfa.losses.TripletSemiHardLoss}\n",")"],"metadata":{"id":"OHxKZITk93Ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.0001),\n","    loss=tfa.losses.TripletSemiHardLoss()\n",")"],"metadata":{"id":"guOESSr5_BWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 80\n","gen_train = tf.data.Dataset.from_tensor_slices((X_train_model, y_train_model)).shuffle(2048).batch(batch_size).repeat()"],"metadata":{"id":"ml2IOitB_HPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpoint_callback = ModelCheckpoint(\n","    '/content/drive/MyDrive/facenet_ver4.h5',\n","    monitor='loss',\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='min',\n","    verbose=1\n",")"],"metadata":{"id":"pPdCtuVO_MP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    gen_train,\n","    steps_per_epoch=30,\n","    epochs=50,\n","    callbacks=[checkpoint_callback]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J6dqkNzh_Q00","outputId":"f4ee2f4f-8599-42c1-85d4-896bdf0cc519"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","30/30 [==============================] - ETA: 0s - loss: 0.5874 \n","Epoch 1: loss improved from inf to 0.58743, saving model to /content/drive/MyDrive/facenet_ver4.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/30 [==============================] - 1407s 47s/step - loss: 0.5874\n","Epoch 2/50\n","30/30 [==============================] - ETA: 0s - loss: 0.4771 \n","Epoch 2: loss improved from 0.58743 to 0.47707, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1377s 46s/step - loss: 0.4771\n","Epoch 3/50\n","30/30 [==============================] - ETA: 0s - loss: 0.4134 \n","Epoch 3: loss improved from 0.47707 to 0.41344, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1385s 46s/step - loss: 0.4134\n","Epoch 4/50\n","30/30 [==============================] - ETA: 0s - loss: 0.3574 \n","Epoch 4: loss improved from 0.41344 to 0.35739, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1373s 46s/step - loss: 0.3574\n","Epoch 5/50\n","30/30 [==============================] - ETA: 0s - loss: 0.3026 \n","Epoch 5: loss improved from 0.35739 to 0.30258, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1365s 45s/step - loss: 0.3026\n","Epoch 6/50\n","30/30 [==============================] - ETA: 0s - loss: 0.2619 \n","Epoch 6: loss improved from 0.30258 to 0.26192, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1349s 45s/step - loss: 0.2619\n","Epoch 7/50\n","30/30 [==============================] - ETA: 0s - loss: 0.2533 \n","Epoch 7: loss improved from 0.26192 to 0.25331, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1371s 46s/step - loss: 0.2533\n","Epoch 8/50\n","30/30 [==============================] - ETA: 0s - loss: 0.2179 \n","Epoch 8: loss improved from 0.25331 to 0.21793, saving model to /content/drive/MyDrive/facenet_ver4.h5\n","30/30 [==============================] - 1388s 46s/step - loss: 0.2179\n","Epoch 9/50\n","19/30 [==================>...........] - ETA: 8:23 - loss: 0.1889"]}]}]}